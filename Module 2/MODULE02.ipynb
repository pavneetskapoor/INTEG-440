{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><font color=\"gray\">INTEG 440 / 640<br>MODULE 2 of *Doing Computational Social Science*</font>\n",
    "\n",
    "# <font color=\"green\" size=40>ETHICS, PRIVACY, <br>TRANSPARENCY, AND <br>FAIRNESS</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "Dr. [John McLevey](http://www.johnmclevey.com)    \n",
    "Department of Knowledge Integration   \n",
    "Department of Sociology & Legal Studies     \n",
    "University of Waterloo         \n",
    "\n",
    "<hr>\n",
    "\n",
    "* INTEG 440 (Undergraduate): This module is worth <font color='#437AB2'>**8%**</font> of your final grade. The questions in this module add up to 10 points. \n",
    "* INTEG 640 (Graduate): This module is worth <font color='#437AB2'>**5%**</font> of your final grade. The questions in this module add up to 10 points. \n",
    "\n",
    "<hr>\n",
    "\n",
    "# Table of Contents \n",
    "\n",
    "* [Overview](#o)\n",
    "* [Learning Outcomes](#lo) \n",
    "* [Prerequisite Knowledge](#pk) \n",
    "* [Assigned Readings](#ar) \n",
    "* [Question Links](#ql)\n",
    "* [**Ethics, Privacy, Transparency, and Fairness**](#eptf)\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "# Overview  <a id='o'></a>\n",
    "\n",
    "Our ability to collect and analyze large-scale digital data is moving much faster than the norms, rules, and laws that govern ethical research (Salganik 2017). This presents major ethical issues for practicing computational social scientists in all sectors (e.g. academia, government, industry, non-profit). Unlike social scientists who work with more conventional data, we computational social scientists typically have to make judgments about ethics in the context of **ethical uncertainty**. This module is a high-level introduction to some of the challenges in doing research that meets the highest-possible standards of ethics, privacy, transparency, and fairness, and considers ways to overcome those challenges. \n",
    "\n",
    "<hr>\n",
    "\n",
    "# Learning Outcomes  <a id='lo'></a>\n",
    "\n",
    "Upon successful completion of this module, you will be able to: \n",
    "\n",
    "1. Characterize the challenges to doing computational social science research that meets the highest-possible standards of ethics, privacy, transparency, and fairness\n",
    "2. Compare rules-based and principles-based ethical frameworks\n",
    "3. Define the following four principles:\n",
    "    * respect for persons\n",
    "    * beneficence\n",
    "    * justice\n",
    "    * respect for law and the public interest\n",
    "4. Compare consequentialist and deontological approaches to ethics\n",
    "5. Characterize the problem of \"informational risk\"\n",
    "6. Compare privacy with \"contextual integrity\" and \"context-relative informational norms\"\n",
    "7. Explain what makes some models \"Weapons of Math Destruction\" (WMD)\n",
    "8. Explain how a WMD Feedback Loop works \n",
    "\n",
    "<hr>\n",
    "\n",
    "# Prerequisite Knowledge  <a id='pk'></a>\n",
    "\n",
    "Some previous experience with research design, theory, and methods in the social sciences is an asset but is not required. This module does not assume any specific background knowledge. \n",
    "\n",
    "<hr>\n",
    "\n",
    "# Assigned Readings  <a id='ar'></a>\n",
    "\n",
    "This module assumes you have completed the assigned readings, which are listed immediately below. The readings provide a detailed explanation of the core concepts covered in this module. \n",
    "\n",
    "* <font color=\"green\">Chapter 6 ([“Ethics”](https://www.bitbybitbook.com/en/1st-ed/ethics/)) from Matt Salganik’s (2017) *Bit by Bit*. [Available online for free.](https://www.bitbybitbook.com/en/1st-ed/ethics/)</font>\n",
    "\n",
    "* <font color=\"green\">Chapter 1 (“Bomb Parts: What is a Model?”) from Cathy O'Neil's *Weapons of Math Destruction*. Crown Publishers.</font>\n",
    "\n",
    "I recommend that you (1) complete the assigned readings, (2) attempt to complete this module without consulting the readings, making notes to indicate where you are uncertain, (3) go back to the readings to fill in the gaps in your knowledge, and finally (4) attempt to complete the parts of this module that you were unable to complete the first time around.\n",
    "\n",
    "This module notebook includes highly condensed overviews of *some* of the key material from the assigned reading. This is intended as a *supplement* to the assigned reading, *not as a replacement for it*. These high-level summaries do not contain enough information for you to successfully complete the exercises that are part of this module, and they do not cover every relevant topic. \n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "# Question Links <a id='ql'></a>\n",
    "\n",
    "Make sure you have answered all of the following questions before submitting this notebook on LEARN. \n",
    "\n",
    "1. [Question 1](#yt1) \n",
    "2. [Question 2](#yt2) \n",
    "3. [Question 3](#yt3) \n",
    "4. [Question 4](#yt4) \n",
    "5. [Question 5](#yt5)\n",
    "6. [Question 6](#yt6) \n",
    "7. [Question 7](#yt7)\n",
    "8. [Question 8](#yt8) \n",
    "9. [Question 9](#yt9) \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics, Privacy, Transparency, and Fairness <a id='eptf'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 1)</font> <a id='yt1'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">1 point</font>\n",
    "\n",
    "When it comes to research ethics, Salganik argues that \"digital is different.\" What does he mean by this and what are the implications for how we do computational social science? Record your response in the cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matt Salganik argues the digital age is different since the scale at which research is being done and the respective tools are different than the analog age alongside the power that researchers hold while it's definitive guidelines are ambigious in definition. The power of researchers, in collaboration with large instituions, alongside the lack of guidance in rules, laws, and norms lead to severe implications (unanticipated secondary use of data, surveillance and intervention in privacy, etc.) These implications are a product of the inconsistency between power and guidelines for which Salganik advises to reference previously developed constructs/frameworks of ethics in order to determine the best possible way forward in research. Implementing principles and frameworks (consequentalism, deontology) within the process of research development and execution are crucial for creating effective guardrails and promoting critical analysis of potential implications in a realm of uncertainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 2)</font> <a id='yt2'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">1 point</font>\n",
    "\n",
    "As mentioned in the [module overview](#o), we computational social scientists have to make a lot of decisions in the context of ethical uncertainty. To help improve the quality of our ethical decision making, Salganik argues in favor of a principles-based approach over a more traditional rules-based approach. In the cell below, describe the difference between these two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tradition rules-based approach is argued by Salganik as being native to the social scientist who does more of a conventional form of research in regards to estalished rules and guidelines. In the digital age however, the rise of data scientists and their respective usage of data in an adhoc approach has led to the consideration of a general principles-based approach where existing rules are to be used in conjunction with generalistic ethical principles. With a principles-driven approach, Salganik argues that researchers can go beyond just the rulebooks and provide an informative reasoning as to their research for themselves and the public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 3)</font> <a id='yt3'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">1 point</font>\n",
    "\n",
    "Salganik discusses four principles that should be central to a principles-based approach for ethical decision making in computational social science: (1) respect for persons, (2) beneficence, (3) justice, and (4) respect for law and the public interest. In the cell below, explain what each of these four principles mean and provide an example of each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respect For Persons\n",
    "\n",
    "Consists of two principles.\n",
    "> 1. Individuals should be treated as autonomous \n",
    "> 2. Individuals with diminished autonomy should be subject to additional protections\n",
    "\n",
    "Respect for persons is in relation to the autonomy (essentially, informed consent) of participants who are potentially taking part in the research. This principle holds in allowing participants to control their decision making process and be adequately notified of relevant information. \n",
    "\n",
    "*Example*\n",
    "For example, there was no informed consent during the Emotional Contagion imposed by researchers in order for participants to gain awareness of the experimentation going on. In this perspective, this is a violation of such principle since participants are not allowed to control their decision in joining control groups that affect their emotion. \n",
    "\n",
    "### Beneficence \n",
    "\n",
    "Consists of Two Principles: \n",
    "> 1. Do not harms\n",
    "> 2. Maximize Possible Benefits and Minimize Possible Harms \n",
    "\n",
    "In regards to research, researchers should implement a risk/benefits analysis and subsequently consider if there is an appropriate balance between the risks and benefits to further proceed the reseaarch. \n",
    "\n",
    "*Example*\n",
    "For example, Mathematica (from Cathy O'Neil's book on WMD), could've added another layer of analysis towards their research in measuring some form of socioeconomic condition among students and their general trend among other courses in order to make a more informed decision of the teacher's performance status. This would add as a benefit for teachers by making far more justified and plausible decisions that would be indicative of teachers and students.\n",
    "\n",
    "### Justice \n",
    "\n",
    "Justice is making sure that the distribution of the associated benefits and risks within the research are fair spread. This is in relation to protection, appropriate compensation, and access to benefits as part of the research. \n",
    "\n",
    "*Example*\n",
    "In the case of Mathematica, the associate benefits and risks in analysing the performance of teachers based on student academic performance led to a larger risk for teachers as they were not adequately compensated with equally-weighted data to support their case for a good teacher. \n",
    "\n",
    "\n",
    "### Respect for Law and Public Interest \n",
    "\n",
    "Consists of two components:\n",
    "> 1. Compliance \n",
    "> 2. Transparency-based Accountability\n",
    "\n",
    "Researchers should and try to be cognizant of respective laws, regulations, and contracts. In regards to such, researchers should employ critical thinking to identify the validity and practicality of laws and regulations in order to effectively see their research through a wider lens. Secondly, researchers should be clear in their intention of research and explain their goals, methodology, and research to ensure there is accountability among the public and no secretive action. \n",
    "\n",
    "*Example*\n",
    "Such example lies within the issue at Netflix, where over a 100 million ratings by 500k+ members was not thoroughly anonymized and led to revealing sensitive member information through re-identification attacks. This didn't serve in the interest of the public as there was not enough guard rails around privacy to ensure anonymity of Netflix users and their respective likings. Subsequently, if researchers are not transparent of using such data for research, society is not informed of their intention and the findings that can be potentially sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 4)</font> <a id='yt4'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">1 point</font>\n",
    "\n",
    "Salganik argues that many ethical disagreements are due to underlying differences between consequentialist and deontological ethical frameworks. In the cell below, compare these two frameworks and explain what, if anything, computational social scientists can get from each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequential ethical frameworks are in relation to focusing on taking actions towards a better state within the world while a deontological ethical framework focuses on ethical duty/conduct that is to be fulfilled. The former is specific to the means of going about research while the latter is specific to the ends. On a spectrum between both such frameworks, focuing on means over ends or vice versa is detrimental to conducting effective research. Inhabiting a mix of both frameworks in conjunction with four principles to make informed decisions in the ethics of research.  If one takes a consequential approach, they will consider the risks and benefits associated to the research and participants while a deontological approach involves sidelining risk/benefits to consider the duty of ethics involved in research. To do a mix of both approaches means including the four principles aformentioned in order to enable reasoning within research and evaluate trade-offs effectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 5)</font> <a id='yt5'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">1 point</font>\n",
    "\n",
    "What is \"informational risk\" and how might computational social scientists reduce it? Record your response in the cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informational risk is associated to the disclosure of information at the expense of risk due to sensitivity and personal comfort. Due to the increase of behavioral data within the digital age, any data collected and distributed can be prone to risks and malicious secondary use In order to avoid informational risk, researchers must follow an adequate data protection plan and consider the sensitivity in data through means of encoding or adequate anonymization. For protecting data among distribution, scientists can employ a walled garden approach and develop a criterion for people to whom data should be released in an ethically-balanced manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 6)</font> <a id='yt6'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">2 points</font>\n",
    "\n",
    "\"Privacy\" is clearly an important right, yet it can be a surprisingly difficult concept to pin down in a research context. In the cell below, explain what the challenges around \"privacy\" are and compare the general concept of privacy to the concepts of \"contextual integrity\" and \"context-relative informational norms.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Privacy is a complex topic due to the underlying perspectives that define what privacy means. The traditional public/private dichotomoy does not help to explain the principle of privacy and the context for which it is being considered in. It is not merely the availability of the data which dictates the adherence to participant/people privacy. Contextual integrity on the other hand considers the flow of information and the three key parameters within the respective flow: actors, attributes, and principles for transmission. Determining privacy through this framework and placing emphasis on the three parameters helps to govern/assess the flow of information in the hollistic context of the research. However, it is hard to consider such parameters in early-measures of research being done since it's hard to establish the actors,attributes, and transmission principles alongside the validity each hold in the larger context/intention of the research. Additionally, privacy is subject to opinion when looked at through a principles-based approach when specifically measuring upon the spectrum of means vs ends (consequentalism vs deontology) which results in misinterpretation and ambiguity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 7)</font> <a id='yt7'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">1 point</font>\n",
    "\n",
    "The central concept in Cathy O'Neil's book *Weapons of Math Destruction* is, unsurprisingly, \"weapons of math destruction* (WMD). What exactly is a WMD? How do WMDs differ from other types of mathematical and computational models (e.g. the models used in major league baseball). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WMD, as explained by Cathy O'Neil, are mathematical and computational models that are opaque and became the center point of controlling the decisions as the standard for ultimate truth. Other mathematical/computational models such as a MLB (major league baseball) model have transparent and relevant updated data for analysis that is levelled and equal among all. Conclusions or assumptions drawn within the model themselves are transparent and clearly depict their intention in comparison to the blackboxes that WMDs are. Apart from opacity, the scale and damage that WMDs cause has now become much larger with prison LSI-R questionairre and Search Algorithms for relevant examples. The companies that operate such WMDs do not disclose their interest and could be potentially discriminatory to certain demographics which leads to question the welfare WMDs act in (many could suffer and many could benefit).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 8)</font> <a id='yt8'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">1 point</font>\n",
    "\n",
    "O'Neil tells the story of Sarah Wysocki and 205 other teachers from Washington DC who lost their jobs because of scores they received from a \"Value Added Model\" developed by a data science company called Mathematica. In the cell below, explain how this particular case illustrates the idea of a **WMD Feedback Loop**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value-added model was flawed and faulty in it's algorithm from the initial phase which was the catalyst to a destructive feedback loop where flawed decisions would keep repeating themselves. As the decision process repeats itself, the model becomes more unfair as it doesn't consider the circumstances and conditions of students in their performance and the general impression of teachers. Since teachers are evaluated on the notion of academic success among students, the model never truly learns of faulty model decisions and thus inevitably goes down a destructive loop where it does not learn from previous error. Each time, underperforming teachers are subject to being failures among the system while gaining a negative performance record further causing detrimental effects to their career. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">YOUR TURN! (Question 9)</font> <a id='yt9'></a>\n",
    "\n",
    "Question is Worth: <font color=\"green\">1 point</font>\n",
    "\n",
    "Cathy O'Neil argues that all models include embedded opinions, values, and even political ideologies. What does she mean by this argument? Be sure to provide examples in your response. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inherently, models, by their assumptions and conclusions, include opinions, values, and political ideologies imposed by the creators. It's almost natural that each tweak in paramteter, each result, each input, is derived from a value or desire which controls the model; since models are made by humans with respective values, opinions, and ideologies. For example, Facebook during the election was notoriously highlighted for imposing political bias through it's ads model which caused controversy and debate as to how the 2016 election had gone due to the increasing reliability that political campaigns have on social channels. By which the model is composed and operates, there was opacity into the model by which Facebook conducts advertising on their revenue model which led to the surge of political advertisements thus priming users. Facebook favors revenue (with over a billion dollars annual revenue) over ethical duty, which shos through their decisions such as refusing to fact check political advertisements. In relation to Cathy O'Neil's argument, this clearly shows how models are inherently opinonated and show political ideology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# <font color=\"green\">Do You See Something That Could Be Better?</font>\n",
    "\n",
    "I am committed to collecting student feedback to continuously improve this course for future students. I would like to invite you to help me make those improvements. \n",
    "\n",
    "As you worked on this module, did you notice anything that could be improved? For example, did you find a typo in the module notebook? Did you find the explanation of a particular concept or block of code confusing? Is there something that just isn’t clicking for you? \n",
    "\n",
    "If you have any feedback for the content in this module, please enter it into the text block below. I will review feedback each week and make a list of things that should be changed before the next offering. \n",
    "\n",
    "Please know that *nothing you say here, however critical, will impact how I evaluate your work in this course*. There is no risk that I will assign a lower grade to you if you provide critical feedback. In fact, if the feedback you provide is thoughtful and constructive, I will assign up to 3% bonus marks on your final course grade. \n",
    "\n",
    "Thanks for your help improving the course! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Feedback Here :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
